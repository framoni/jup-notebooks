{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Kaggle APTOS 2019 Challenge\n\nAPTOS 2019 is a challenge hosted by Kaggle where the goal is to classify fundus (eye retina) images of diabetic rethinopatic patients according to the severity of their disease on a scale 0 (minimum severity) to 4 (maximum severity).\n\nThis notebook illustrates the model I submitted which achieved a final QWK (Quadratic Weighted Kappa) score of 0.9 (maximum score being 1).\n\n* model: EfficientNet B5\n* no cropping or equalization\n* augmentation: flipud, fliplr, zoom, rotation\n* no TTA (worse results)"},{"metadata":{},"cell_type":"markdown","source":"### Load libraries"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import os\nimport sys\nsys.path.append(os.path.abspath('../input/efficientnetkeras/efficientnet-master')) # from https://github.com/qubvel/efficientnet\n\nimport cv2\nimport efficientnet.keras as efn\nimport json\nfrom keras.activations import elu\nfrom keras.callbacks import Callback\nfrom keras.layers import Dense, Dropout, GlobalAveragePooling2D\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score\nimport tensorflow as tf\nfrom tqdm import tqdm","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Set parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nEN_size = 224\nseed = 1990","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Set random seed"},{"metadata":{"trusted":true},"cell_type":"code","source":"random.seed(seed)\ntf.set_random_seed(seed)","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_15 = pd.read_csv('../input/diabetic-retinopathy-resized/trainLabels.csv')\nlabels_15.rename(columns={\"image\": \"id_code\", \"level\": \"diagnosis\"}, inplace=True)\nlabels_15['path'] = '../input/diabetic-retinopathy-resized/resized_train/resized_train' + '/' + labels_15['id_code'] + '.jpeg'\n\nidx = labels_15[labels_15['diagnosis']==0].index.to_list()\nidx = random.sample(idx, k=len(idx)-10000) # cut class 0 examples for more balance and to reduce training time\nlabels_15.drop(idx, inplace=True)\n\nlabels_19 = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\nlabels_19['path'] = '../input/aptos2019-blindness-detection/train_images' + '/' + labels_19['id_code'] + '.png'\n\ntrain_df = pd.concat([labels_15, labels_19])\n\ntrain_df['diagnosis'].hist()\nplt.title('Training labels distribution')\ntrain_df['diagnosis'].value_counts()\n\nx = train_df[['path']]\ny = train_df['diagnosis']","execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"### Function to open and resize images"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_image(path):\n    img = Image.open(path)\n    img = img.resize((EN_size, EN_size), resample=Image.LANCZOS)\n    return img","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.15, stratify=y, random_state=seed)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_val_arr = np.empty((x_val.shape[0], EN_size, EN_size, 3), dtype=np.uint8)\n\nfor i, row in tqdm(x_val.reset_index().iterrows(), total=len(x_val)):\n    try:\n        x_val_arr[i, :, :, :] = preprocess_image(row['path'])\n    except:\n        pass","execution_count":13,"outputs":[{"output_type":"stream","text":"100%|██████████| 3447/3447 [02:16<00:00, 25.31it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.DataFrame(pd.concat([x_train, pd.DataFrame(y_train)], axis=1), columns=['path', 'diagnosis'])","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create data generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_datagen():\n    return ImageDataGenerator(\n        zoom_range=0.25,\n        rotation_range=180,\n        fill_mode='constant',\n        cval=0.,\n        horizontal_flip=True,\n        vertical_flip=True,\n        width_shift_range=.05,\n        height_shift_range=.05\n    )\n\ntrain_generator = create_datagen().flow_from_dataframe(\n    train_df,\n    x_col='path',\n    y_col='diagnosis',\n    target_size=(EN_size, EN_size),\n    class_mode='other',\n    batch_size=batch_size,\n    seed=seed,\n    interpolation=\"lanczos\",\n    drop_duplicates=True\n    )","execution_count":15,"outputs":[{"output_type":"stream","text":"Found 19531 validated image filenames.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Create Keras callback for QWK score"},{"metadata":{"trusted":true},"cell_type":"code","source":"class QWK(Callback):\n\n    def on_train_begin(self, logs={}):\n        self.val_kappas = []\n        \n    def on_epoch_end(self, epoch, logs={}):\n        x_val, y_val = self.validation_data[:2]\n        \n        y_pred = self.model.predict(x_val)\n        \n        coeff = [0.5, 1.5, 2.5, 3.5]\n\n        for i, pred in enumerate(y_pred):\n            if pred < coeff[0]:\n                y_pred[i] = 0\n            elif pred >= coeff[0] and pred < coeff[1]:\n                y_pred[i] = 1\n            elif pred >= coeff[1] and pred < coeff[2]:\n                y_pred[i] = 2\n            elif pred >= coeff[2] and pred < coeff[3]:\n                y_pred[i] = 3\n            else:\n                y_pred[i] = 4\n\n        _val_kappa = cohen_kappa_score(\n            y_val,\n            y_pred, \n            weights='quadratic'\n        )\n\n        self.val_kappas.append(_val_kappa)\n\n        print(f\"val_kappa: {_val_kappa:.4f}\")\n        \n        if _val_kappa == max(self.val_kappas):\n            print(\"Validation Kappa has improved. Saving model.\")\n            self.model.save('model.h5')\n\n        return","execution_count":16,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model: EfficientNet B5"},{"metadata":{"trusted":true},"cell_type":"code","source":"effnet = efn.EfficientNetB5(\n    weights=None,\n    include_top=False,\n    input_shape=(EN_size, EN_size, 3)\n)\n\neffnet.load_weights('../input/efficientnet-keras-weights-b0b5/efficientnet-b5_imagenet_1000_notop.h5')","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    \n    model = Sequential()\n    model.add(effnet)\n    model.add(GlobalAveragePooling2D())\n    model.add(Dropout(0.5))\n    model.add(Dense(5, activation=\"elu\"))\n    model.add(Dense(1, activation=\"linear\"))\n    model.compile(loss='mse', optimizer=Adam(lr=1e-4), metrics=['mse'])\n    \n    return model","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model()\nmodel.summary()","execution_count":19,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nefficientnet-b5 (Model)      (None, 7, 7, 2048)        28513520  \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 2048)              0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 2048)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 5)                 10245     \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 6         \n=================================================================\nTotal params: 28,523,771\nTrainable params: 28,351,035\nNon-trainable params: 172,736\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Training and evaluation of the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"qwk = QWK()\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=x_train.shape[0] / batch_size,\n    epochs=15,\n    validation_data=(x_val_arr, y_val),\n    callbacks=[qwk]\n)","execution_count":20,"outputs":[{"output_type":"stream","text":"Epoch 1/15\n611/610 [==============================] - 1235s 2s/step - loss: 1.0948 - mean_squared_error: 1.0948 - val_loss: 0.7673 - val_mean_squared_error: 0.7673\nval_kappa: 0.6015\nValidation Kappa has improved. Saving model.\nEpoch 2/15\n345/610 [===============>..............] - ETA: 7:55 - loss: 0.8334 - mean_squared_error: 0.8334","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-a8e450c7445c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mqwk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('model.h5')","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('history.json', 'w') as f:\n    json.dump(history.history, f)\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot\n\nplt.plot(qwk.val_kappas)","execution_count":22,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'history' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-e2b2f6f47e69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'history.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhistory_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhistory_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"]}]},{"metadata":{},"cell_type":"markdown","source":"### Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N = test_df.shape[0]\nx_test = np.empty((N, EN_size, EN_size, 3), dtype=np.uint8)\n\nfor i, img_id in enumerate(tqdm(test_df['id_code'])):\n    x_test[i, :, :, :] = preprocess_image(f'../input/aptos2019-blindness-detection/test_images/{img_id}.png')","execution_count":24,"outputs":[{"output_type":"stream","text":"  6%|▌         | 114/1928 [00:05<01:39, 18.20it/s]\n","name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-aff6c7b0c605>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id_code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'../input/aptos2019-blindness-detection/test_images/{img_id}.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-941a4063b395>\u001b[0m in \u001b[0;36mpreprocess_image\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEN_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEN_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLANCZOS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box)\u001b[0m\n\u001b[1;32m   1802\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1804\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = model.predict(x_test)\n\ncoeff = [0.5, 1.5, 2.5, 3.5]\n\nfor i, pred in enumerate(y_test):\n    if pred < coeff[0]:\n        y_test[i] = 0\n    elif pred >= coeff[0] and pred < coeff[1]:\n        y_test[i] = 1\n    elif pred >= coeff[1] and pred < coeff[2]:\n        y_test[i] = 2\n    elif pred >= coeff[2] and pred < coeff[3]:\n        y_test[i] = 3\n    else:\n        y_test[i] = 4\n\ntest_df['diagnosis'] = y_test.astype(int)\ntest_df.to_csv('submission.csv', index=False)\n\ntest_df['diagnosis'].hist()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}